{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Diabetes Prediction with Neural Network in Keras",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfy43vHOsc1z"
      },
      "source": [
        "### Sai Kiran Singh Thakur [0755575]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELCyNUT2YLWv"
      },
      "source": [
        "#### This machine learning project is about Diabetes Prediction. We would be working on kaggle pima indians diabetes dataset. https://www.kaggle.com/uciml/pima-indians-diabetes-database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scNHr1Z2YjkC"
      },
      "source": [
        "#### The necessary packages are imported."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJiGTDLTYB9g"
      },
      "source": [
        "# Importing the necessary packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zuuo3xSrYuvq"
      },
      "source": [
        "#### The dataset is read into ‘df’ dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7kdzhPjYqc_"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Projects/diabetes _pima.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRmurM4hZUqm"
      },
      "source": [
        "#### Let us understand the dataframe ‘df’."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waKo6jxQZTGB",
        "outputId": "3f8c8d9f-a0e8-4ea3-c29c-8321e15ed7ff"
      },
      "source": [
        "df.shape # Shape of ‘df’"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5e2rgStZdH4"
      },
      "source": [
        "#### The size is (768,9) which suggests there are 768 cases and 9 columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac8afoYYZcXz",
        "outputId": "7c93c4d7-aa43-46e6-dc21-55e01538159f"
      },
      "source": [
        "df.columns # Prints columns of ‘df’"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmdZ3OhgZrRX"
      },
      "source": [
        "#### The columns are [‘Pregnancies’, ‘Glucose’, ‘BloodPressure’, ‘SkinThickness’, ‘Insulin’, ‘BMI’, ‘DiabetesPedigreeFunction’, ‘Age’, ‘Outcome’]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "uyfDBr7rZvy4",
        "outputId": "eafad4fa-a697-4c64-dea6-f833437a102c"
      },
      "source": [
        "df.describe() # Displays properties of each column"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>120.894531</td>\n",
              "      <td>69.105469</td>\n",
              "      <td>20.536458</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>31.992578</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>0.348958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.369578</td>\n",
              "      <td>31.972618</td>\n",
              "      <td>19.355807</td>\n",
              "      <td>15.952218</td>\n",
              "      <td>115.244002</td>\n",
              "      <td>7.884160</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>0.476951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Pregnancies     Glucose  ...         Age     Outcome\n",
              "count   768.000000  768.000000  ...  768.000000  768.000000\n",
              "mean      3.845052  120.894531  ...   33.240885    0.348958\n",
              "std       3.369578   31.972618  ...   11.760232    0.476951\n",
              "min       0.000000    0.000000  ...   21.000000    0.000000\n",
              "25%       1.000000   99.000000  ...   24.000000    0.000000\n",
              "50%       3.000000  117.000000  ...   29.000000    0.000000\n",
              "75%       6.000000  140.250000  ...   41.000000    1.000000\n",
              "max      17.000000  199.000000  ...   81.000000    1.000000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkQJATC7aKKZ"
      },
      "source": [
        "#### All the columns have count = 768 which suggests there are no missing values. The mean of ‘Outcome’ is 0.35 which suggests there are more ‘Outcome’ = 0 than ‘Outcome’ = 1 cases in the given dataset.\n",
        "#### The dataframe ‘df’ is converted into numpy array ‘dataset’"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2IAZ6L8aNBu"
      },
      "source": [
        "dataset = df.values"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2oawgcQagZD"
      },
      "source": [
        "#### The ‘dataset’ is split into input X and output y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n6wFKe-alZ1"
      },
      "source": [
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8].astype('int')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gLjrLHybBSM"
      },
      "source": [
        "#### Standardization\n",
        "#### It can be observed that mean value of columns are very different. Hence the dataset is to be standardized so that no inappropriate weightage is given to any feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45I1Q_V1bS_9"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzJIKzAsbJAP"
      },
      "source": [
        "# Standardization\n",
        "a = StandardScaler()\n",
        "a.fit(X)\n",
        "X_standardized = a.transform(X)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovnXpZI3bhgw"
      },
      "source": [
        "#### Now let us look at mean and standard deviation of ‘X_standardized’."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "t8OI9XjibphC",
        "outputId": "a0a3ade7-74da-4f36-9165-03f373508425"
      },
      "source": [
        "pd.DataFrame(X_standardized).describe()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.544261e-17</td>\n",
              "      <td>3.614007e-18</td>\n",
              "      <td>-1.327244e-17</td>\n",
              "      <td>7.994184e-17</td>\n",
              "      <td>-3.556183e-17</td>\n",
              "      <td>2.295979e-16</td>\n",
              "      <td>2.398978e-16</td>\n",
              "      <td>1.857600e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.141852e+00</td>\n",
              "      <td>-3.783654e+00</td>\n",
              "      <td>-3.572597e+00</td>\n",
              "      <td>-1.288212e+00</td>\n",
              "      <td>-6.928906e-01</td>\n",
              "      <td>-4.060474e+00</td>\n",
              "      <td>-1.189553e+00</td>\n",
              "      <td>-1.041549e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-8.448851e-01</td>\n",
              "      <td>-6.852363e-01</td>\n",
              "      <td>-3.673367e-01</td>\n",
              "      <td>-1.288212e+00</td>\n",
              "      <td>-6.928906e-01</td>\n",
              "      <td>-5.955785e-01</td>\n",
              "      <td>-6.889685e-01</td>\n",
              "      <td>-7.862862e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-2.509521e-01</td>\n",
              "      <td>-1.218877e-01</td>\n",
              "      <td>1.496408e-01</td>\n",
              "      <td>1.545332e-01</td>\n",
              "      <td>-4.280622e-01</td>\n",
              "      <td>9.419788e-04</td>\n",
              "      <td>-3.001282e-01</td>\n",
              "      <td>-3.608474e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.399473e-01</td>\n",
              "      <td>6.057709e-01</td>\n",
              "      <td>5.632228e-01</td>\n",
              "      <td>7.190857e-01</td>\n",
              "      <td>4.120079e-01</td>\n",
              "      <td>5.847705e-01</td>\n",
              "      <td>4.662269e-01</td>\n",
              "      <td>6.602056e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.906578e+00</td>\n",
              "      <td>2.444478e+00</td>\n",
              "      <td>2.734528e+00</td>\n",
              "      <td>4.921866e+00</td>\n",
              "      <td>6.652839e+00</td>\n",
              "      <td>4.455807e+00</td>\n",
              "      <td>5.883565e+00</td>\n",
              "      <td>4.063716e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0             1  ...             6             7\n",
              "count  7.680000e+02  7.680000e+02  ...  7.680000e+02  7.680000e+02\n",
              "mean   2.544261e-17  3.614007e-18  ...  2.398978e-16  1.857600e-16\n",
              "std    1.000652e+00  1.000652e+00  ...  1.000652e+00  1.000652e+00\n",
              "min   -1.141852e+00 -3.783654e+00  ... -1.189553e+00 -1.041549e+00\n",
              "25%   -8.448851e-01 -6.852363e-01  ... -6.889685e-01 -7.862862e-01\n",
              "50%   -2.509521e-01 -1.218877e-01  ... -3.001282e-01 -3.608474e-01\n",
              "75%    6.399473e-01  6.057709e-01  ...  4.662269e-01  6.602056e-01\n",
              "max    3.906578e+00  2.444478e+00  ...  5.883565e+00  4.063716e+00\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9hDAs_nb6aj"
      },
      "source": [
        "#### Mean of all columns is around 0 and Standard deviation of all columns is around 1. The data has been standardized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ntN8h1uepgc"
      },
      "source": [
        "### Tuning of Hyperparameters :- Batch Size and Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL4ZR27cb5Hw"
      },
      "source": [
        "# Importing the necessary packages\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3fQ1PnDijOU"
      },
      "source": [
        "from keras.models import Sequential"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhjJ1PKyfWy5"
      },
      "source": [
        "#### The neural architecture and optimization algorithm are defined. The neural network consists of 1 input layer, 2 hidden layers with rectified linear unit activation function and 1 output layer with sigmoid activation function. Adams optimization is chosen as the optimization algorithm for the neural network model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEo6KB_JfaNo"
      },
      "source": [
        "# Defining a model\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(8,input_dim = 8, kernel_initializer='normal',activation='relu'))\n",
        "  model.add(Dense(4,input_dim = 8, kernel_initializer='normal',activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  adam = Adam(lr = 0.01)\n",
        "  model.compile(loss = 'binary_crossentropy',optimizer=adam, metrics = ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCblAfGFg9oE"
      },
      "source": [
        "#### We run the grid search for 2 hyperparameters :- ‘batch_size’ and ‘epochs’. The cross validation technique used is K-Fold with the default value k = 3. The accuracy score is calculated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrX4kXlehFv3"
      },
      "source": [
        "# Create the model\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
        "# Define the grid search parameters\n",
        "batch_size = [10,20,40]\n",
        "epochs = [10,50,100]\n",
        "# Make a dictionary of the grid search parameters\n",
        "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
        "# Build and fit the GridSearchCV\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOGnDq0ripgO",
        "outputId": "40206578-f6a2-499c-8ada-22303bedace5"
      },
      "source": [
        "grid_result = grid.fit(X_standardized,y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] batch_size=10, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=10, score=0.714, total=   1.9s\n",
            "[CV] batch_size=10, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=10, score=0.675, total=   1.2s\n",
            "[CV] batch_size=10, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=10, score=0.740, total=   1.2s\n",
            "[CV] batch_size=10, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=10, score=0.824, total=   1.2s\n",
            "[CV] batch_size=10, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    5.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=10, score=0.752, total=   1.2s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=50, score=0.753, total=   3.4s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   10.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=50, score=0.688, total=   3.2s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   13.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=50, score=0.747, total=   3.3s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   16.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=50, score=0.810, total=   3.2s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   19.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............ batch_size=10, epochs=50, score=0.765, total=   3.2s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n",
            "[CV] ........... batch_size=10, epochs=100, score=0.734, total=   5.8s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n",
            "[CV] ........... batch_size=10, epochs=100, score=0.662, total=   5.8s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n",
            "[CV] ........... batch_size=10, epochs=100, score=0.740, total=   5.8s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n",
            "[CV] ........... batch_size=10, epochs=100, score=0.817, total=   5.8s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n",
            "[CV] ........... batch_size=10, epochs=100, score=0.771, total=   6.1s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] ............ batch_size=20, epochs=10, score=0.753, total=   0.9s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] ............ batch_size=20, epochs=10, score=0.734, total=   0.9s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] ............ batch_size=20, epochs=10, score=0.779, total=   1.0s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] ............ batch_size=20, epochs=10, score=0.850, total=   1.0s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] ............ batch_size=20, epochs=10, score=0.758, total=   1.0s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] ............ batch_size=20, epochs=50, score=0.740, total=   2.0s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] ............ batch_size=20, epochs=50, score=0.701, total=   2.0s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] ............ batch_size=20, epochs=50, score=0.773, total=   2.0s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] ............ batch_size=20, epochs=50, score=0.771, total=   2.2s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] ............ batch_size=20, epochs=50, score=0.765, total=   2.0s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ........... batch_size=20, epochs=100, score=0.734, total=   3.3s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ........... batch_size=20, epochs=100, score=0.714, total=   3.4s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ........... batch_size=20, epochs=100, score=0.766, total=   3.4s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ........... batch_size=20, epochs=100, score=0.817, total=   3.3s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ........... batch_size=20, epochs=100, score=0.771, total=   3.4s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "[CV] ............ batch_size=40, epochs=10, score=0.734, total=   0.8s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "[CV] ............ batch_size=40, epochs=10, score=0.727, total=   0.8s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "[CV] ............ batch_size=40, epochs=10, score=0.766, total=   1.1s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "[CV] ............ batch_size=40, epochs=10, score=0.843, total=   0.8s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "[CV] ............ batch_size=40, epochs=10, score=0.765, total=   0.8s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] ............ batch_size=40, epochs=50, score=0.734, total=   1.4s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] ............ batch_size=40, epochs=50, score=0.708, total=   1.4s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] ............ batch_size=40, epochs=50, score=0.773, total=   1.4s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] ............ batch_size=40, epochs=50, score=0.804, total=   1.4s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] ............ batch_size=40, epochs=50, score=0.784, total=   1.4s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ........... batch_size=40, epochs=100, score=0.734, total=   2.3s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ........... batch_size=40, epochs=100, score=0.734, total=   2.1s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ........... batch_size=40, epochs=100, score=0.753, total=   2.1s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ........... batch_size=40, epochs=100, score=0.817, total=   2.1s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ........... batch_size=40, epochs=100, score=0.758, total=   2.1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.8min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3fLsc0NlTqk"
      },
      "source": [
        "#### The results are summarized. The best accuracy score and the best values of hyperparameters are printed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eal2PC_KlSL3",
        "outputId": "d2c978fe-261e-4dc4-f187-0570cca6371e"
      },
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best : 0.7748153805732727, using {'batch_size': 20, 'epochs': 10}\n",
            "0.7410067200660706,0.048890971090362494 with: {'batch_size': 10, 'epochs': 10}\n",
            "0.7526950240135193,0.039144832479853044 with: {'batch_size': 10, 'epochs': 50}\n",
            "0.7449198007583618,0.05070185744005769 with: {'batch_size': 10, 'epochs': 100}\n",
            "0.7748153805732727,0.040125827151960634 with: {'batch_size': 20, 'epochs': 10}\n",
            "0.7500466942787171,0.027021042861549244 with: {'batch_size': 20, 'epochs': 50}\n",
            "0.7605042099952698,0.03518586998961425 with: {'batch_size': 20, 'epochs': 100}\n",
            "0.7670231819152832,0.04119579221817774 with: {'batch_size': 40, 'epochs': 10}\n",
            "0.7605042099952698,0.034913711156882216 with: {'batch_size': 40, 'epochs': 50}\n",
            "0.7591885328292847,0.030562519764402402 with: {'batch_size': 40, 'epochs': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbCmhdC3lmbR"
      },
      "source": [
        "#### The best accuracy score is 0.77 for ‘batch_size’ = 20 and ‘epochs’ = 10. So we choose ‘batch_size’ = 40 and ‘epochs’ = 10 while tuning other hyperparameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkeWXfzGlsbq"
      },
      "source": [
        "### Tuning of Hyperparameters:- Learning rate and Drop out rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxCbZINun-SM"
      },
      "source": [
        "#### The learning rate plays an important role in optimization algorithm. If the learning rate is too large, the algorithm may diverge and thus can’t find the local optima. If the learning rate is too small, the algorithm may take many iterations to converge which results in high computational power and time. Thus we need an optimum value of learning rate which is small enough for the algorithm to converge and large enough to fasten the converging process. The learning rate helps with ‘Early Stopping’ which is a regularization method where the training set is trained as long as test set accuracy is increasing.\n",
        "#### Drop out is a regularization method that reduces the complexity of the model and thus prevents overfitting the training data. By dropping an activation unit out, we mean temporarily removing it from the network, along with all its incoming and outgoing connections. Dropout rate can take values between 0 and 1. 0 implies no activation units are knocked out and 1 implies all the activation units are knocked out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0mAbqXNlk25",
        "outputId": "3f5e8aef-38f8-42c8-8e02-3e091211796f"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "\n",
        "# Defining the model\n",
        "\n",
        "def create_model(learning_rate,dropout_rate):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8,input_dim = 8,kernel_initializer = 'normal',activation = 'relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(4,input_dim = 8,kernel_initializer = 'normal',activation = 'relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = learning_rate)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
        "\n",
        "# Define the grid search parameters\n",
        "\n",
        "learning_rate = [0.001,0.01,0.1]\n",
        "dropout_rate = [0.0,0.1,0.2]\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "\n",
        "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,y)\n",
        "\n",
        "# Summarize the results\n",
        "\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.753, total=   0.9s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.584, total=   0.9s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.773, total=   0.9s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.824, total=   1.2s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    3.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.647, total=   0.9s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    4.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.734, total=   0.9s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    5.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.708, total=   0.9s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    6.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.753, total=   0.9s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    7.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.843, total=   0.9s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    8.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.765, total=   0.9s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.727, total=   0.9s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.708, total=   1.2s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.766, total=   0.9s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.791, total=   0.9s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.732, total=   0.9s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.766, total=   0.9s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.656, total=   0.9s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.747, total=   0.9s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.824, total=   0.9s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.647, total=   1.1s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.740, total=   0.9s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.714, total=   0.9s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.766, total=   0.9s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.837, total=   0.9s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.784, total=   0.9s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.766, total=   0.9s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.727, total=   0.9s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.760, total=   0.9s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.804, total=   1.2s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.765, total=   0.9s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.766, total=   0.9s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.584, total=   0.9s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.760, total=   0.9s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.837, total=   0.9s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.712, total=   0.9s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.734, total=   0.9s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.721, total=   1.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.766, total=   0.9s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.843, total=   0.9s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.765, total=   0.9s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.760, total=   0.9s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.714, total=   0.9s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.740, total=   0.9s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.699, total=   0.9s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.797, total=   1.1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   42.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best : 0.7683388590812683, using {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
            "0.7161955595016479,0.08744716578965923 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
            "0.7605296730995178,0.045589506230784754 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
            "0.7448349118232727,0.029731881479920428 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
            "0.7278838872909545,0.0673754325281089 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
            "0.7683388590812683,0.04154411508954742 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
            "0.764374840259552,0.024353868374445174 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
            "0.731881833076477,0.0837226922976347 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "0.7657244801521301,0.04250985434373287 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
            "0.7422035574913025,0.03456157914427266 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4AWS3UOoZ5Y"
      },
      "source": [
        "#### The best accuracy score is 0.7695 for ‘dropout_rate’ = 0.1 and ‘learning_rate’ = 0.001. So we choose ‘dropout_rate’ = 0.1 and ‘learning_rate’ = 0.01 while tuning other hyperparameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOyRabxwo5pE"
      },
      "source": [
        "### Tuning of Hyperparameters:- Activation Function and Kernel Initializer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlX8LOLro8cr"
      },
      "source": [
        "#### Activation functions introduce non-linear properties to the neural network such that non-linear complex functional mappings between input and output can be established. If we do not apply the activation function, then the output would be a simple linear function of the input.\n",
        "#### The neural network needs to start with some weights and then iteratively update them to better values. Kernel initializer decides the statistical distribution or function to be used for initializing the weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVJcEIj7od54",
        "outputId": "1c23ea1b-90db-4e0e-f6dd-0a3ad8608d57"
      },
      "source": [
        "\n",
        "# Defining the model\n",
        "\n",
        "def create_model(activation_function,init):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8,input_dim = 8,kernel_initializer = init,activation = activation_function))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(4,input_dim = 8,kernel_initializer = init,activation = activation_function))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = 0.001)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
        "\n",
        "# Define the grid search parameters\n",
        "\n",
        "activation_function = ['softmax','relu','tanh','linear']\n",
        "init = ['uniform','normal','zero']\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "\n",
        "param_grids = dict(activation_function = activation_function,init = init)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,y)\n",
        "\n",
        "# Summarize the results\n",
        "\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "[CV] activation_function=softmax, init=uniform .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=uniform, score=0.351, total=   1.0s\n",
            "[CV] activation_function=softmax, init=uniform .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=uniform, score=0.416, total=   0.9s\n",
            "[CV] activation_function=softmax, init=uniform .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=uniform, score=0.630, total=   0.9s\n",
            "[CV] activation_function=softmax, init=uniform .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=uniform, score=0.745, total=   1.0s\n",
            "[CV] activation_function=softmax, init=uniform .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    3.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=uniform, score=0.647, total=   0.9s\n",
            "[CV] activation_function=softmax, init=normal ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    4.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=normal, score=0.649, total=   0.9s\n",
            "[CV] activation_function=softmax, init=normal ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    5.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=normal, score=0.416, total=   1.2s\n",
            "[CV] activation_function=softmax, init=normal ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    6.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=normal, score=0.370, total=   0.9s\n",
            "[CV] activation_function=softmax, init=normal ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    7.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=normal, score=0.745, total=   0.9s\n",
            "[CV] activation_function=softmax, init=normal ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    8.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=normal, score=0.647, total=   0.9s\n",
            "[CV] activation_function=softmax, init=zero ..........................\n",
            "[CV]  activation_function=softmax, init=zero, score=0.649, total=   0.9s\n",
            "[CV] activation_function=softmax, init=zero ..........................\n",
            "[CV]  activation_function=softmax, init=zero, score=0.584, total=   0.9s\n",
            "[CV] activation_function=softmax, init=zero ..........................\n",
            "[CV]  activation_function=softmax, init=zero, score=0.630, total=   0.9s\n",
            "[CV] activation_function=softmax, init=zero ..........................\n",
            "[CV]  activation_function=softmax, init=zero, score=0.255, total=   0.9s\n",
            "[CV] activation_function=softmax, init=zero ..........................\n",
            "[CV]  activation_function=softmax, init=zero, score=0.647, total=   0.9s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=0.727, total=   1.2s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=0.714, total=   0.9s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=0.760, total=   0.9s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=0.797, total=   0.9s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=0.784, total=   0.9s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=0.779, total=   0.9s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=0.584, total=   0.9s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=0.760, total=   0.9s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=0.745, total=   0.9s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=0.647, total=   1.2s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV] . activation_function=relu, init=zero, score=0.649, total=   0.9s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV] . activation_function=relu, init=zero, score=0.584, total=   0.9s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV] . activation_function=relu, init=zero, score=0.630, total=   0.9s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV] . activation_function=relu, init=zero, score=0.745, total=   0.9s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV] . activation_function=relu, init=zero, score=0.647, total=   0.9s\n",
            "[CV] activation_function=tanh, init=uniform ..........................\n",
            "[CV]  activation_function=tanh, init=uniform, score=0.753, total=   0.9s\n",
            "[CV] activation_function=tanh, init=uniform ..........................\n",
            "[CV]  activation_function=tanh, init=uniform, score=0.708, total=   0.9s\n",
            "[CV] activation_function=tanh, init=uniform ..........................\n",
            "[CV]  activation_function=tanh, init=uniform, score=0.747, total=   0.9s\n",
            "[CV] activation_function=tanh, init=uniform ..........................\n",
            "[CV]  activation_function=tanh, init=uniform, score=0.837, total=   1.1s\n",
            "[CV] activation_function=tanh, init=uniform ..........................\n",
            "[CV]  activation_function=tanh, init=uniform, score=0.778, total=   0.9s\n",
            "[CV] activation_function=tanh, init=normal ...........................\n",
            "[CV]  activation_function=tanh, init=normal, score=0.740, total=   0.9s\n",
            "[CV] activation_function=tanh, init=normal ...........................\n",
            "[CV]  activation_function=tanh, init=normal, score=0.682, total=   0.9s\n",
            "[CV] activation_function=tanh, init=normal ...........................\n",
            "[CV]  activation_function=tanh, init=normal, score=0.753, total=   0.9s\n",
            "[CV] activation_function=tanh, init=normal ...........................\n",
            "[CV]  activation_function=tanh, init=normal, score=0.810, total=   0.9s\n",
            "[CV] activation_function=tanh, init=normal ...........................\n",
            "[CV]  activation_function=tanh, init=normal, score=0.758, total=   0.9s\n",
            "[CV] activation_function=tanh, init=zero .............................\n",
            "[CV] . activation_function=tanh, init=zero, score=0.649, total=   0.9s\n",
            "[CV] activation_function=tanh, init=zero .............................\n",
            "[CV] . activation_function=tanh, init=zero, score=0.584, total=   0.9s\n",
            "[CV] activation_function=tanh, init=zero .............................\n",
            "[CV] . activation_function=tanh, init=zero, score=0.630, total=   1.2s\n",
            "[CV] activation_function=tanh, init=zero .............................\n",
            "[CV] . activation_function=tanh, init=zero, score=0.745, total=   0.9s\n",
            "[CV] activation_function=tanh, init=zero .............................\n",
            "[CV] . activation_function=tanh, init=zero, score=0.647, total=   0.9s\n",
            "[CV] activation_function=linear, init=uniform ........................\n",
            "[CV]  activation_function=linear, init=uniform, score=0.753, total=   0.9s\n",
            "[CV] activation_function=linear, init=uniform ........................\n",
            "[CV]  activation_function=linear, init=uniform, score=0.682, total=   0.9s\n",
            "[CV] activation_function=linear, init=uniform ........................\n",
            "[CV]  activation_function=linear, init=uniform, score=0.773, total=   0.9s\n",
            "[CV] activation_function=linear, init=uniform ........................\n",
            "[CV]  activation_function=linear, init=uniform, score=0.824, total=   0.9s\n",
            "[CV] activation_function=linear, init=uniform ........................\n",
            "[CV]  activation_function=linear, init=uniform, score=0.771, total=   0.9s\n",
            "[CV] activation_function=linear, init=normal .........................\n",
            "[CV]  activation_function=linear, init=normal, score=0.747, total=   1.2s\n",
            "[CV] activation_function=linear, init=normal .........................\n",
            "[CV]  activation_function=linear, init=normal, score=0.701, total=   0.9s\n",
            "[CV] activation_function=linear, init=normal .........................\n",
            "[CV]  activation_function=linear, init=normal, score=0.734, total=   0.9s\n",
            "[CV] activation_function=linear, init=normal .........................\n",
            "[CV]  activation_function=linear, init=normal, score=0.804, total=   0.9s\n",
            "[CV] activation_function=linear, init=normal .........................\n",
            "[CV]  activation_function=linear, init=normal, score=0.752, total=   0.9s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=0.649, total=   0.9s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=0.584, total=   0.9s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=0.630, total=   0.9s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=0.745, total=   1.2s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=0.647, total=   0.9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   56.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best : 0.7644342660903931, using {'activation_function': 'tanh', 'init': 'uniform'}\n",
            "0.5576521575450897,0.14925036447256432 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
            "0.5654443681240082,0.14600163439375066 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
            "0.5531194269657135,0.15092304368625437 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
            "0.7565996170043945,0.031912271011245504 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
            "0.703106689453125,0.07482370087428578 with: {'activation_function': 'relu', 'init': 'normal'}\n",
            "0.6511586427688598,0.05244526932680711 with: {'activation_function': 'relu', 'init': 'zero'}\n",
            "0.7644342660903931,0.04250231170874071 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
            "0.7487904310226441,0.041155117274727544 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
            "0.6511586427688598,0.05244526932680711 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
            "0.7605126857757568,0.045784359352845874 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
            "0.7474747657775879,0.033239174605898404 with: {'activation_function': 'linear', 'init': 'normal'}\n",
            "0.6511586427688598,0.05244526932680711 with: {'activation_function': 'linear', 'init': 'zero'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLDMUtwVqVjr"
      },
      "source": [
        "#### Best : 0.7644342660903931, using {'activation_function': 'tanh', 'init': 'uniform'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm7hd8zJp7uH"
      },
      "source": [
        "### Tuning of Hyperparameter :-Number of Neurons in activation layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUYwOtqAp75O"
      },
      "source": [
        "#### The complexity of the data has to be matched with the complexity of the model. The number of neurons in activation layer decides the complexity of the model. Higher the number of neurons in activation layer, higher is the degree of non-linear complex functional mappings between input and output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLlW6fCzlSPP",
        "outputId": "ecc5ea78-a1bf-49f4-b997-6a75294fc322"
      },
      "source": [
        "\n",
        "# Defining the model\n",
        "\n",
        "def create_model(neuron1,neuron2):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neuron1,input_dim = 8,kernel_initializer = 'uniform',activation = 'tanh'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = 0.001)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
        "\n",
        "# Define the grid search parameters\n",
        "\n",
        "neuron1 = [4,8,16]\n",
        "neuron2 = [2,4,8]\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "\n",
        "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,y)\n",
        "\n",
        "# Summarize the results\n",
        "\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print('{},{} with: {}'.format(mean, stdev, param))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.753, total=   1.0s\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.688, total=   0.9s\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.727, total=   0.9s\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.797, total=   0.9s\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    3.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.732, total=   0.9s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    4.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.760, total=   0.9s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    5.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.688, total=   1.2s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    6.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.734, total=   0.9s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    7.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.804, total=   0.9s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    8.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.758, total=   0.9s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=4, neuron2=8, score=0.760, total=   0.9s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=4, neuron2=8, score=0.688, total=   0.9s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=4, neuron2=8, score=0.747, total=   0.9s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=4, neuron2=8, score=0.810, total=   0.9s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=4, neuron2=8, score=0.765, total=   0.9s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.760, total=   1.1s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.675, total=   0.9s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.740, total=   0.9s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.804, total=   0.9s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.745, total=   0.9s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.753, total=   0.9s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.675, total=   0.9s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.760, total=   0.9s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.830, total=   0.9s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.765, total=   1.2s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.753, total=   0.9s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.701, total=   0.9s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.760, total=   0.9s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.830, total=   0.9s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.771, total=   0.9s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.766, total=   0.9s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.708, total=   0.9s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.753, total=   0.9s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.824, total=   1.2s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.765, total=   0.9s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.760, total=   0.9s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.734, total=   0.9s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.753, total=   0.9s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.817, total=   0.9s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.765, total=   0.9s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.766, total=   0.9s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.721, total=   0.9s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.760, total=   1.2s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.817, total=   0.9s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.745, total=   0.9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   41.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best : 0.7656905174255371, using {'neuron1': 16, 'neuron2': 4}\n",
            "0.7396485924720764,0.03567972803381991 with: {'neuron1': 4, 'neuron2': 2}\n",
            "0.748781943321228,0.0377643216776258 with: {'neuron1': 4, 'neuron2': 4}\n",
            "0.7539937257766723,0.03924917074305466 with: {'neuron1': 4, 'neuron2': 8}\n",
            "0.7448688626289368,0.0413909917439262 with: {'neuron1': 8, 'neuron2': 2}\n",
            "0.7566165804862977,0.04917244783910581 with: {'neuron1': 8, 'neuron2': 4}\n",
            "0.763118577003479,0.04117869030834061 with: {'neuron1': 8, 'neuron2': 8}\n",
            "0.763101601600647,0.036932781092794596 with: {'neuron1': 16, 'neuron2': 2}\n",
            "0.7656905174255371,0.027721382162182215 with: {'neuron1': 16, 'neuron2': 4}\n",
            "0.7617689490318298,0.0317234086840922 with: {'neuron1': 16, 'neuron2': 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_rDMA85qd4e"
      },
      "source": [
        "#### Best : 0.7656905174255371, using {'neuron1': 16, 'neuron2': 4}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZnU0L8Yqj7p"
      },
      "source": [
        "### Training model with optimum values of Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUjICMFYqo_Q"
      },
      "source": [
        "#### The model is trained using optimum values of hyperparameters found in previous section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxNcGKUEqlwE",
        "outputId": "34e920aa-9ad7-433a-f5d5-f2738f7f0b56"
      },
      "source": [
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Defining the model\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(16,input_dim = 8,kernel_initializer = 'uniform',activation = 'tanh'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(4,input_dim = 16,kernel_initializer = 'uniform',activation = 'tanh'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = 0.001)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
        "\n",
        "# Fitting the model\n",
        "\n",
        "model.fit(X_standardized,y)\n",
        "\n",
        "# Predicting using trained model\n",
        "\n",
        "y_predict = model.predict(X_standardized)\n",
        "\n",
        "# Printing the metrics\n",
        "\n",
        "print(accuracy_score(y,y_predict))\n",
        "print(classification_report(y,y_predict))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7760416666666666\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.88      0.84       500\n",
            "           1       0.73      0.57      0.64       268\n",
            "\n",
            "    accuracy                           0.78       768\n",
            "   macro avg       0.76      0.73      0.74       768\n",
            "weighted avg       0.77      0.78      0.77       768\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwsf0SqYq5_2"
      },
      "source": [
        "#### We get an accuracy of 77.6% and F1 scores of 0.84 and 0.64.\n",
        "#### The hyperparameter optimization was carried out by taking 2 hyperparameters at once. We may have missed the best values. The performance can be further improved by finding the optimum values of hyperparameters all at once given by the code snippet below. Note:- This process is computationally expensive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "bTJrK-r5ql4F",
        "outputId": "1d7e3242-085e-4221-ed66-724893645b55"
      },
      "source": [
        "\n",
        "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neuron1,input_dim = 8,kernel_initializer = init,activation = activation_function))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = learning_rate)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
        "\n",
        "# Define the grid search parameters\n",
        "\n",
        "batch_size = [10,20,40]\n",
        "epochs = [10,50,100]\n",
        "learning_rate = [0.001,0.01,0.1]\n",
        "dropout_rate = [0.0,0.1,0.2]\n",
        "activation_function = ['softmax','relu','tanh','linear']\n",
        "init = ['uniform','normal','zero']\n",
        "neuron1 = [4,8,16]\n",
        "neuron2 = [2,4,8]\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "\n",
        "param_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,dropout_rate = dropout_rate,\n",
        "                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,y)\n",
        "\n",
        "# Summarize the results\n",
        "\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8, score=0.758, total=   6.4s\n",
            "[CV] activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2 \n",
            "[CV]  activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2, score=0.727, total=   6.2s\n",
            "[CV] activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2 \n",
            "[CV]  activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2, score=0.695, total=   6.3s\n",
            "[CV] activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2 \n",
            "[CV]  activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2, score=0.766, total=   6.2s\n",
            "[CV] activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-d106d9d8cd54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_standardized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Summarize the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}